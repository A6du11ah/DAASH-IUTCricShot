{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q71CjHEt4gyj",
        "outputId": "bc0fdc18-2ee6-462a-d02c-464c79d12f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGUcm6_epue4",
        "outputId": "2d35bf08-739e-4702-9fdf-d6aa1ab2624f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltdLUXrpyt2h",
        "outputId": "1f0b9dca-955f-48a3-d454-19b3af864720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnqqC7xH4pQ6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Sequential\n",
        "from tensorflow.keras.layers import TimeDistributed, LSTM, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetB0, EfficientNetV2B0, EfficientNetV2S\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o41DA6uoNfQw"
      },
      "outputs": [],
      "source": [
        "def load_video_paths_with_label(data_dir):\n",
        "    labels = {'Defensive Shot': 0, 'Pull Shot': 1, 'Drive Shot': 2, 'Flick Shot': 3}\n",
        "    video_paths_with_label = {}\n",
        "\n",
        "    for label in tqdm(labels):\n",
        "        videos_dir = os.path.join(data_dir, label)\n",
        "        videos = os.listdir(videos_dir)\n",
        "\n",
        "        video_paths_with_label[labels[label]] = []\n",
        "\n",
        "        for video in videos:\n",
        "            video_path = os.path.join(videos_dir, video)\n",
        "            video_paths_with_label[labels[label]].append(video_path)\n",
        "\n",
        "    return video_paths_with_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaeIP7eO_Ecz"
      },
      "outputs": [],
      "source": [
        "def prepare_train_test_split(video_paths_with_label, test_size=0.2, random_state=42):\n",
        "    paths_train = []\n",
        "    paths_test = []\n",
        "    labels_train = []\n",
        "    labels_test = []\n",
        "\n",
        "    for label in tqdm(video_paths_with_label):\n",
        "        label_video_paths = video_paths_with_label[label]\n",
        "        label_paths_train, label_paths_val = train_test_split(label_video_paths, test_size=test_size, random_state=random_state)\n",
        "\n",
        "        paths_train.extend(label_paths_train)\n",
        "        paths_test.extend(label_paths_val)\n",
        "\n",
        "        labels_train.extend([label] * len(label_paths_train))\n",
        "        labels_test.extend([label] * len(label_paths_val))\n",
        "\n",
        "    return paths_train, paths_test, labels_train, labels_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcvfoHeA8jpB"
      },
      "outputs": [],
      "source": [
        "def preprocess_video(video_path, num_frames=16, frame_size=(224, 224)):\n",
        "    # Load the video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the interval to extract the required number of frames\n",
        "    frame_interval = max(total_frames // num_frames, 1)\n",
        "\n",
        "    for i in range(0, total_frames, frame_interval):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Resize the frame\n",
        "        frame = cv2.resize(frame, frame_size)\n",
        "        # Normalize the frame (scaling pixel values to [0, 1])\n",
        "        # frame = frame.astype('float32') / 255.0\n",
        "        frames.append(frame)\n",
        "\n",
        "        # Stop if we have enough frames\n",
        "        if len(frames) == num_frames:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Ensure we have exactly num_frames by padding with the last frame if necessary\n",
        "    while len(frames) < num_frames:\n",
        "        frames.append(frames[-1])\n",
        "\n",
        "    # Convert to numpy array\n",
        "    frames = np.array(frames)\n",
        "    # Add batch dimension\n",
        "    # frames = np.expand_dims(frames, axis=0)\n",
        "    return frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPRscN443BBN"
      },
      "outputs": [],
      "source": [
        "def video_data_generator(video_paths, labels, num_frames=16, frame_size=(224, 224)):\n",
        "    batch_videos = []\n",
        "    batch_labels = []\n",
        "\n",
        "    for idx in tqdm(range(len(labels))):\n",
        "        video_path = video_paths[idx]\n",
        "        frames = preprocess_video(video_path, num_frames, frame_size)\n",
        "\n",
        "        batch_videos.append(frames)\n",
        "        batch_labels.append(labels[idx])\n",
        "\n",
        "    # batch_videos = np.vstack(batch_videos)\n",
        "    batch_videos = np.array(batch_videos)\n",
        "    batch_labels = np.array(batch_labels)\n",
        "\n",
        "    return batch_videos, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lnECDFNpSJI"
      },
      "outputs": [],
      "source": [
        "def prepare_train_test_data():\n",
        "    frame_size = (224, 224)\n",
        "    frame_channel = 3\n",
        "    num_frames = 16\n",
        "\n",
        "    data_dir = '/content/drive/My Drive/ShotDetection'\n",
        "    data_paths = load_video_paths_with_label(data_dir)\n",
        "\n",
        "    paths_train, paths_test, labels_train, labels_test = prepare_train_test_split(data_paths)\n",
        "\n",
        "    X_train, y_train = video_data_generator(paths_train, labels_train, num_frames, frame_size)\n",
        "    X_test, y_test = video_data_generator(paths_test, labels_test, num_frames, frame_size)\n",
        "\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], num_frames, frame_size[0], frame_size[1], frame_channel))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], num_frames, frame_size[0], frame_size[1], frame_channel))\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KUiyaxfv_Le",
        "outputId": "3fe08cdb-b595-4392-86b5-e0ad621fcdbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 14.59it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 1021.20it/s]\n",
            "100%|██████████| 1020/1020 [11:36<00:00,  1.46it/s]\n",
            "100%|██████████| 258/258 [03:04<00:00,  1.39it/s]\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train, X_test, y_test = prepare_train_test_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsTkgvG5yG1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278fd737-193e-4c47-fc95-6025e651bcac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1020, 16, 224, 224, 3)\n",
            "(1020,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2jEhuPtz-p8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d652532-5849-41a0-955f-691376b387fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(258, 16, 224, 224, 3)\n",
            "(258,)\n"
          ]
        }
      ],
      "source": [
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBg01ISKDYG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d42f6e4-5216-4e65-8271-0b53242aacaf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ4NgQm88HAm"
      },
      "outputs": [],
      "source": [
        "# def mb_conv_block(x, filters, kernel_size, strides, expansion, block_id):\n",
        "#     shortcut = x\n",
        "#     prefix = 'block_{}_'.format(block_id)\n",
        "\n",
        "#     # Expansion phase\n",
        "#     if expansion != 1:\n",
        "#         x = layers.Conv3D(expansion * x.shape[-1], 1, padding='same', use_bias=False, name=prefix + 'expand')(x)\n",
        "#         x = layers.BatchNormalization(name=prefix + 'expand_bn')(x)\n",
        "#         x = layers.Activation('relu', name=prefix + 'expand_relu')(x)\n",
        "\n",
        "#     # Depthwise Convolution\n",
        "#     x = layers.Conv3D(filters, kernel_size, strides=strides, padding='same', use_bias=False, name=prefix + 'dwconv')(x)\n",
        "#     x = layers.BatchNormalization(name=prefix + 'dwconv_bn')(x)\n",
        "#     x = layers.Activation('relu', name=prefix + 'dwconv_relu')(x)\n",
        "\n",
        "#     # Project\n",
        "#     x = layers.Conv3D(filters, 1, padding='same', use_bias=False, name=prefix + 'project')(x)\n",
        "#     x = layers.BatchNormalization(name=prefix + 'project_bn')(x)\n",
        "\n",
        "#     if strides == 1 and shortcut.shape[-1] == filters:\n",
        "#         x = layers.Add(name=prefix + 'add')([shortcut, x])\n",
        "\n",
        "#     return x\n",
        "\n",
        "# def create_MAT_effNet_model(input_shape=(16, 224, 224, 3), num_classes=101):\n",
        "#     inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "#     # Stage 0\n",
        "#     x = inputs\n",
        "\n",
        "#     # Stage 1\n",
        "#     x = layers.Conv3D(32, (3, 3, 3), strides=(1, 2, 2), padding='same', name='stage1_conv')(x)\n",
        "#     x = layers.BatchNormalization(name='stage1_bn')(x)\n",
        "#     x = layers.Activation('relu', name='stage1_relu')(x)\n",
        "\n",
        "#     # Stage 2\n",
        "#     x = mb_conv_block(x, 16, (3, 3, 3), 1, 1, 2)\n",
        "\n",
        "#     # Stage 3\n",
        "#     x = mb_conv_block(x, 24, (3, 3, 3), (1, 2, 2), 6, 3)\n",
        "#     x = mb_conv_block(x, 24, (3, 3, 3), 1, 6, 4)\n",
        "\n",
        "#     # Stage 4\n",
        "#     x = mb_conv_block(x, 40, (5, 5, 5), (1, 2, 2), 6, 5)\n",
        "#     x = mb_conv_block(x, 40, (5, 5, 5), 1, 6, 6)\n",
        "\n",
        "#     # Stage 5\n",
        "#     x = mb_conv_block(x, 80, (3, 3, 3), (1, 2, 2), 6, 7)\n",
        "#     x = mb_conv_block(x, 80, (3, 3, 3), 1, 6, 8)\n",
        "#     x = mb_conv_block(x, 80, (3, 3, 3), 1, 6, 9)\n",
        "\n",
        "#     # Stage 6\n",
        "#     x = mb_conv_block(x, 112, (5, 5, 5), 1, 6, 10)\n",
        "#     x = mb_conv_block(x, 112, (5, 5, 5), 1, 6, 11)\n",
        "#     x = mb_conv_block(x, 112, (5, 5, 5), 1, 6, 12)\n",
        "\n",
        "#     # Stage 7\n",
        "#     x = mb_conv_block(x, 192, (5, 5, 5), (1, 2, 2), 6, 13)\n",
        "#     x = mb_conv_block(x, 192, (5, 5, 5), 1, 6, 14)\n",
        "#     x = mb_conv_block(x, 192, (5, 5, 5), 1, 6, 15)\n",
        "#     x = mb_conv_block(x, 192, (5, 5, 5), 1, 6, 16)\n",
        "\n",
        "#     # Stage 8\n",
        "#     x = mb_conv_block(x, 320, (3, 3, 3), 1, 6, 17)\n",
        "\n",
        "#     # Stage 9\n",
        "#     x = layers.Conv3D(1280, 1, padding='same', name='stage9_conv')(x)\n",
        "#     x = layers.BatchNormalization(name='stage9_bn')(x)\n",
        "#     x = layers.Activation('relu', name='stage9_relu')(x)\n",
        "#     x = layers.GlobalAveragePooling3D(name='stage9_pool')(x)\n",
        "\n",
        "#     # Stage 10: Multi-head attention layer\n",
        "#     x = layers.Reshape((1, 1280))(x)\n",
        "#     attention_output = layers.MultiHeadAttention(num_heads=8, key_dim=128, name='attention_layer')(x, x)\n",
        "#     x = layers.Reshape((512,))(attention_output)\n",
        "\n",
        "#     # Stage 11: Fully connected layer and softmax\n",
        "#     outputs = layers.Dense(num_classes, activation='softmax', name='fc_softmax')(x)\n",
        "\n",
        "#     model = models.Model(inputs, outputs)\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoDu6AgJFlT7"
      },
      "outputs": [],
      "source": [
        "# def mb_conv_block(x, filters, kernel_size, strides, expansion, block_id):\n",
        "#     shortcut = x\n",
        "#     prefix = 'block_{}_'.format(block_id)\n",
        "\n",
        "#     # Expansion phase\n",
        "#     if expansion != 1:\n",
        "#         x = layers.Conv2D(expansion * x.shape[-1], 1, padding='same', use_bias=False, name=prefix + 'expand')(x)\n",
        "#         x = layers.BatchNormalization(name=prefix + 'expand_bn')(x)\n",
        "#         x = layers.Activation('relu', name=prefix + 'expand_relu')(x)\n",
        "\n",
        "#     # Depthwise Convolution\n",
        "#     x = layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=False, name=prefix + 'dwconv')(x)\n",
        "#     x = layers.BatchNormalization(name=prefix + 'dwconv_bn')(x)\n",
        "#     x = layers.Activation('relu', name=prefix + 'dwconv_relu')(x)\n",
        "\n",
        "#     # Project\n",
        "#     x = layers.Conv2D(filters, 1, padding='same', use_bias=False, name=prefix + 'project')(x)\n",
        "#     x = layers.BatchNormalization(name=prefix + 'project_bn')(x)\n",
        "\n",
        "#     if strides == 1 and shortcut.shape[-1] == filters:\n",
        "#         x = layers.Add(name=prefix + 'add')([shortcut, x])\n",
        "\n",
        "#     return x\n",
        "\n",
        "# def create_MAT_effNet_model(input_shape=(16, 224, 224, 3), num_classes=101):\n",
        "#     inputs = layers.Input(shape=input_shape)\n",
        "#     x = inputs\n",
        "#     frames = []\n",
        "\n",
        "#     # Process each frame individually\n",
        "#     for i in range(input_shape[0]):\n",
        "#         frame = layers.Lambda(lambda x: x[:, i])(x)\n",
        "\n",
        "#         # Stage 1\n",
        "#         frame = layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', name=f'stage1_conv_{i}')(frame)\n",
        "#         frame = layers.BatchNormalization(name=f'stage1_bn_{i}')(frame)\n",
        "#         frame = layers.Activation('relu', name=f'stage1_relu_{i}')(frame)\n",
        "\n",
        "#         # Stage 2\n",
        "#         frame = mb_conv_block(frame, 16, (3, 3), 1, 1, f'2_{i}')\n",
        "\n",
        "#         # Stage 3\n",
        "#         frame = mb_conv_block(frame, 24, (3, 3), 2, 6, f'3_{i}')\n",
        "#         frame = mb_conv_block(frame, 24, (3, 3), 1, 6, f'4_{i}')\n",
        "\n",
        "#         # Stage 4\n",
        "#         frame = mb_conv_block(frame, 40, (5, 5), 2, 6, f'5_{i}')\n",
        "#         frame = mb_conv_block(frame, 40, (5, 5), 1, 6, f'6_{i}')\n",
        "\n",
        "#         # Stage 5\n",
        "#         frame = mb_conv_block(frame, 80, (3, 3), 2, 6, f'7_{i}')\n",
        "#         frame = mb_conv_block(frame, 80, (3, 3), 1, 6, f'8_{i}')\n",
        "#         frame = mb_conv_block(frame, 80, (3, 3), 1, 6, f'9_{i}')\n",
        "\n",
        "#         # Stage 6\n",
        "#         frame = mb_conv_block(frame, 112, (5, 5), 1, 6, f'10_{i}')\n",
        "#         frame = mb_conv_block(frame, 112, (5, 5), 1, 6, f'11_{i}')\n",
        "#         frame = mb_conv_block(frame, 112, (5, 5), 1, 6, f'12_{i}')\n",
        "\n",
        "#         # Stage 7\n",
        "#         frame = mb_conv_block(frame, 192, (5, 5), 2, 6, f'13_{i}')\n",
        "#         frame = mb_conv_block(frame, 192, (5, 5), 1, 6, f'14_{i}')\n",
        "#         frame = mb_conv_block(frame, 192, (5, 5), 1, 6, f'15_{i}')\n",
        "#         frame = mb_conv_block(frame, 192, (5, 5), 1, 6, f'16_{i}')\n",
        "\n",
        "#         # Stage 8\n",
        "#         frame = mb_conv_block(frame, 320, (3, 3), 1, 6, f'17_{i}')\n",
        "\n",
        "#         # Stage 9\n",
        "#         frame = layers.Conv2D(1280, 1, padding='same', name=f'stage9_conv_{i}')(frame)\n",
        "#         frame = layers.BatchNormalization(name=f'stage9_bn_{i}')(frame)\n",
        "#         frame = layers.Activation('relu', name=f'stage9_relu_{i}')(frame)\n",
        "#         frame = layers.GlobalAveragePooling2D(name=f'stage9_pool_{i}')(frame)\n",
        "\n",
        "#         frames.append(frame)\n",
        "\n",
        "#     # Combine frames\n",
        "#     x = tf.stack(frames, axis=1)  # shape: (batch_size, num_frames, 1280)\n",
        "\n",
        "#     # Stage 10: Multi-head attention layer\n",
        "#     attention_output = layers.MultiHeadAttention(num_heads=8, key_dim=128, name='attention_layer')(x, x)\n",
        "#     x = layers.Reshape((input_shape[0], -1))(attention_output)  # Flatten along the last dimension\n",
        "\n",
        "#     # Stage 11: Fully connected layer and softmax\n",
        "#     outputs = layers.Dense(num_classes, activation='softmax', name='fc_softmax')(x)\n",
        "\n",
        "#     model = models.Model(inputs, outputs)\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwLv5iUKSsnH"
      },
      "outputs": [],
      "source": [
        "# def create_MAT_effNet_model(input_shape=(16, 224, 224, 3), num_classes=101):\n",
        "#     base_model = EfficientNetB0(include_top=False, weights=None, input_shape=input_shape[1:])\n",
        "#     base_model.trainable = True\n",
        "\n",
        "#     inputs = layers.Input(shape=input_shape)\n",
        "#     frames = []\n",
        "\n",
        "#     # Process each frame individually\n",
        "#     for i in range(input_shape[0]):\n",
        "#         frame = layers.Lambda(lambda x: x[:, i])(inputs)\n",
        "#         frame = base_model(frame, training=False)\n",
        "#         frame = layers.GlobalAveragePooling2D()(frame)\n",
        "#         frames.append(frame)\n",
        "\n",
        "#     # Combine frames\n",
        "#     x = tf.stack(frames, axis=1)  # shape: (batch_size, num_frames, 1280)\n",
        "\n",
        "#     # Multi-head attention layer\n",
        "#     attention_output = layers.MultiHeadAttention(num_heads=8, key_dim=128, name='attention_layer')(x, x)\n",
        "#     x = layers.Flatten()(attention_output)  # Flatten along the last dimension\n",
        "\n",
        "#     # Fully connected layer and softmax\n",
        "#     outputs = layers.Dense(num_classes, activation='softmax', name='fc_softmax')(x)\n",
        "\n",
        "#     model = models.Model(inputs, outputs)\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_MAT_effNet_model(input_shape=(16, 224, 224, 3), num_classes=101):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input Layer\n",
        "    model.add(layers.Input(shape=input_shape))\n",
        "\n",
        "    # TimeDistributed EfficientNetB0\n",
        "    base_model = EfficientNetV2B0(include_top=False, weights=None, input_shape=input_shape[1:])\n",
        "    base_model.trainable = True\n",
        "\n",
        "    model.add(TimeDistributed(base_model))\n",
        "    model.add(TimeDistributed(layers.GlobalAveragePooling2D()))\n",
        "\n",
        "    # Combine frames\n",
        "    # For attention, we need to switch from Sequential to functional API for this step\n",
        "    inputs = model.input\n",
        "    x = model.output\n",
        "\n",
        "    # Multi-head attention layer\n",
        "    attention_output = layers.MultiHeadAttention(num_heads=8, key_dim=128, name='attention_layer')(x, x)\n",
        "    x = layers.Flatten()(attention_output)\n",
        "\n",
        "    # Fully connected layer and softmax\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', name='fc_softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "ACVv5RI4_e5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG48_2A8ph9i",
        "outputId": "19759a6e-988a-4c79-db2e-0d997f45360d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 16, 224, 224, 3)]    0         []                            \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, 16, 7, 7, 1280)       4049571   ['input_1[0][0]']             \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDi  (None, 16, 1280)             0         ['time_distributed[0][0]']    \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " attention_layer (MultiHead  (None, 16, 1280)             5247232   ['time_distributed_1[0][0]',  \n",
            " Attention)                                                          'time_distributed_1[0][0]']  \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 20480)                0         ['attention_layer[0][0]']     \n",
            "                                                                                                  \n",
            " fc_softmax (Dense)          (None, 4)                    81924     ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9378727 (35.78 MB)\n",
            "Trainable params: 9336704 (35.62 MB)\n",
            "Non-trainable params: 42023 (164.16 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "num_classes = 4\n",
        "# num_classes = 101  # or 51\n",
        "model = create_MAT_effNet_model(input_shape=input_shape, num_classes=num_classes)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "JA7LIdvW8hBt",
        "outputId": "22905d05-af94-4b4f-ae41-1fad18bcd224"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e3cd727cf1e1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=16)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}